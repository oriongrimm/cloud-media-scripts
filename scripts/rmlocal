#!/bin/sh
#shellcheck source=config
########## CONFIGURATION ##########
. "../config"
###################################
rm_time () {
	# Generate filelist and iterate through it...
	find "${local_dir}" -type f -mtime +$remove_files_older_than |
		while read -r n; do

			# Find the pathname relative to the root of your remote and store filename
			filename="$(echo "$n" | sed -e s@"${local_dir}"@@)"
			destpath="$(dirname "$n" | sed -e s@"${local_dir}"@@)"

			# Skip hidden or partial files.
			case "$n" in
				(*.partial~) continue ;;
				(*_HIDDEN~) continue ;;
				(*.QTFS) continue ;;
				(*.fuse*) continue ;;
				(.DS_STORE) continue ;;
			esac

			# If file is opened by another process, wait until it isn't.
			while [ "$(lsof "$n" >/dev/null 2>&1)" ] || \
				[ "$(lsof "${local_dir}/${n}" >/dev/null 2>&1)" ] || \
				[ "$(lsof "${local_media_dir}/${n}" >/dev/null 2>&1)" ]; do
				echo "[ $(date ${date_format}) ] File -> ${n} in use. Retrying in 10 seconds."
				sleep 10
			done

			# Move file to remote destination[s], retaining path
			echo "[ $(date ${date_format}) ] Moving file -> ${n} to Google Drive."
			"${rclone_bin}" move --config="${rclone_cfg}" "$n" "${rclone_cloud_endpoint}${destpath}" >/dev/null 2>&1
		done
}

rm_space () {
	maxSize=$($remove_files_when_space_exceeds * 1000 * 1000 * 1000)
	currentSize="$(du -sb "$local_dir" | awk '{print $1}')"
	if [ "$maxSize" -gt "$currentSize" ]; then
			echo "Current size of $($currentSize / 1000 / 1000 / 1000) GB has not exceeded $remove_files_when_space_exceeds GB"
			exit 02
	fi

	addedSpace=0
	freeup=$($freeup_atleast * 1000 * 1000 * 1000)

	find "${local_dir}" -type f -exec stat -c "%x %n" {} \; | sort | awk '{$1=$2=$3=""; print $0}' |
		while read -r n; do
			if [ "$addedSpace" -gt "$freeup" ]; then
					spaceInGb=$(($addedSpace / 1000 / 1000 / 1000))
					spaceLeft=$(($(du -sb "$local_dir" | awk '{print $1}') / 1000 / 1000 / 1000))
					echo "[ $(date ${date_format}) ] Removed ${spaceInGb} GB. Media in total ${spaceLeft} GB."
					break
			fi

			# Find the pathname relative to the rsoot of your remote and store filename
			filename="$(echo "$n" | sed -e s@"${local_dir}"@@)"
			destpath="$(dirname "$n" | sed -e s@"${local_dir}"@@)"

			# Skip hidden or partial files.
			case "$n" in
					(*.partial~) continue ;;
					(*_HIDDEN~) continue ;;
					(*.QTFS) continue ;;
					(*.fuse*) continue ;;
					(.DS_STORE) continue ;;
			esac

			# If file is opened by another process, wait until it isn't.
			while [ "$(lsof "$n" >/dev/null 2>&1)" ] || \
					[ "$(lsof "${local_dir}/${n}" >/dev/null 2>&1)" ] || \
					[ "$(lsof "${local_media_dir}/${n}" >/dev/null 2>&1)" ]; do
					echo "[ $(date ${date_format}) ] File -> ${n} in use. Retrying in 10 seconds."
					sleep 10
			done

			echo $n

			fileSize=$(du -sb "$n" | awk '{print $1}')
			addedSpace="$(($addedSpace + $fileSize))"

			fileSizeGb=$(($fileSize / 1000 / 1000 / 1000))

			# Move file to remote destination[s], retaining path
			echo "[ $(date ${date_format}) ] Moving file -> ${n} to Google Drive. Freeing up ${fileSizeGb} GB"
			"${rclone_bin}" move --config="${rclone_cfg}" "$n" "${rclone_cloud_endpoint}${destpath}" >/dev/null 2>&1
	done
}

# If script is already running; abort.
if pidof -o %PPID -x "$(basename "$0")"; then
	echo "[ $(date ${date_format}) ] Upload already in progress. Aborting."
	exit 3
fi

if [ "$remove_files_based_on" = "space" ]; then
	rm_space
elif [ "$remove_files_based_on" = "time" ]; then
	rm_time
else
	echo "[ $(date ${date_format}) ] no option to remove old files"
	exit 02
fi
